---
title: "Resampling: cross-validation and bootstrap (lab 5 for BIOS 26122)"
author: "Dmitry Kondrashov"
format: 
  html:
    self-contained: true
editor: visual
---

## Description

The goal of this assignment is to learn to use and understand regularization methods for multivariate linear regression, such as ridge and LASSO.

The use of these models is demonstrated in the week 6 tutorials using the tools from package `tidymodels`; I recommend that you use them to perform the tasks below.

```{r setup}
#| include: false
#| echo: false
library(tidyverse)
library(tidymodels)
library(faraway)
```

The data set `fat` loaded below from the package `faraway` contains variables age, weight, height, and 10 body circumference measurements measured for 252 men. There are four potential response variables `brozek`, `free`, `siri`, and `density`, which are all highly related measures of body fat percentage.

```{r}
data("fat")
glimpse(fat)
```

## Multivariate regression

1.  First, clean the data to keep only `brozek` of the above response variables and remove any missing values. Second, split the data into training and test sets. Third, perform standard linear regression using `lm` on the training set using `brozek` as the response variable and report which of the predictor variables have the most significant relationship with it.

```{r}
fat_clean <- fat |> 
 dplyr::select(-c(siri, density, free)) |> 
 drop_na()


# Put 3/4 of the data into the training set 
fat_split <- initial_split(fat_clean, prop = 0.75)

# Create data frames for the two sets:
fat_train <- training(fat_split)
fat_test  <- testing(fat_split)

fat_recipe <- 
  recipe(brozek ~ ., data = fat_train)

lm_spec <- linear_reg() |> 
  set_mode("regression") |> 
  set_engine("lm")

workflow_lm <- workflow() |> 
  add_model(lm_spec) |> 
  add_recipe(fat_recipe)

fit_lm <- workflow_lm |> 
  fit(fat_train)

tidy(fit_lm)

# You can also use lm
lm_out <- lm(brozek ~ ., data = fat_train)
summary(lm_out)
```

2.  Calculate the r squared of the predictions on the test set and report them. How does it compare to the r-squared from the summary of lm? Do you see evidence of overfitting?

```{r}
compare_pred <- augment(fit_lm, new_data = fat_test) 

compare_pred |> rsq(brozek, .pred)
```

The r-squared from lm (calculated on the training set) is 0.75 (will vary for different splits) but the r-squared calculated on the test set is about 0.5, so there is evidence of overfitting.

## Ridge regression

3.  Perform ridge regression on the training set using a couple of different values of penalty lambda and report the parameter values and the r-squared on the test set.

```{r}
ridge_spec <- linear_reg(mixture = 0, penalty= 0.1) |> 
  set_mode("regression") |> 
  set_engine("glmnet")

workflow_ridge <- workflow() |> 
  add_model(ridge_spec) |> 
  add_recipe(fat_recipe)

fit_ridge <- workflow_ridge |> 
  fit(fat_train)

print("The parameters and r-squared of the prediction on the test with lambda = 0.1:")

tidy(fit_ridge)

compare_pred <- augment(fit_ridge, new_data = fat_test) 

compare_pred |> rsq(brozek, .pred)


ridge_spec <- linear_reg(mixture = 0, penalty= 1) |> 
  set_mode("regression") |> 
  set_engine("glmnet")

workflow_ridge <- workflow() |> 
  add_model(ridge_spec) |> 
  add_recipe(fat_recipe)

fit_ridge <- workflow_ridge |> 
  fit(fat_train)

print("The parameters and r-squared of the prediction on the test with lambda = 1:")

tidy(fit_ridge)

compare_pred <- augment(fit_ridge, new_data = fat_test) 

compare_pred |> rsq(brozek, .pred)

```

4.  Perform ridge regression on the training set with parameter tuning, using k-fold validation. Make a plot of the rmse and r-squared as a function of lambda and report the best value of lambda.

    ```{r}
    fat_fold <- vfold_cv(fat_train, v = 10)

    ridge_recipe <- 
      recipe(brozek~ ., data = fat_train) |> 
      step_novel(all_nominal_predictors()) |>  
      step_dummy(all_nominal_predictors()) |>  
      step_zv(all_predictors()) |> 
      step_normalize(all_predictors())

    ridge_spec <- 
      linear_reg(penalty= tune(), mixture = 0) |> 
      set_mode("regression") |> 
      set_engine("glmnet")

    ridge_workflow <- workflow() |> 
      add_recipe(ridge_recipe) |> 
      add_model(ridge_spec)


    penalty_grid <- grid_regular(penalty(range = c(-5, 1)), levels = 50)


    tune_res <- tune_grid(
      ridge_workflow,
      resamples = fat_fold, 
      grid = penalty_grid
    )

    autoplot(tune_res)

    collect_metrics(tune_res)

    best_penalty<- select_best(tune_res, metric = "rmse")

    best_penalty

    ```

5.  Get the final model using the best penalty value, generate predictions on the test set, and report the parameter values and the r-squared on the test set.

```{r}
ridge_final <- finalize_workflow(ridge_workflow, best_penalty)

ridge_final_fit <- fit(ridge_final, data = fat_train)

augment(ridge_final_fit, new_data = fat_test) |>
  rsq(truth = brozek, estimate = .pred)

tidy(ridge_final_fit, penalty= best_penalty$penalty)

```

6.  Compare on the performance of ridge regression to plain linear regression in terms of tuning the parameter lambda and the impact it has on the prediction quality on the test set.

Ridge regression does a better job than plain linear regression because it avoids overfitting (due to using k-fold cross-validation), so its r-squared on the test set is considerably higher. The best penalty value is small (will vary depending on the random split) but none of parameters are very small. (Their difference in absolute value from the linear model is due to us having scaled the variables in the recipe using the `step_normalize` function.)

## Regression with LASSO

7.  Perform LASSO regression on the training set using a couple of different values of penalty lambda and report the parameter values and the r-squared on the test set.

```{r}
lasso_spec <- linear_reg(mixture = 1, penalty= 0.1) |> 
  set_mode("regression") |> 
  set_engine("glmnet")

workflow_ridge <- workflow() |> 
  add_model(lasso_spec) |> 
  add_recipe(fat_recipe)

fit_ridge <- workflow_ridge |> 
  fit(fat_train)

print("The parameters and r-squared of the LASSO prediction on the test with lambda = 0.1:")

tidy(fit_ridge)

compare_pred <- augment(fit_ridge, new_data = fat_test) 

compare_pred |> rsq(brozek, .pred)


lasso_spec <- linear_reg(mixture = 1, penalty= 1) |> 
  set_mode("regression") |> 
  set_engine("glmnet")

workflow_ridge <- workflow() |> 
  add_model(lasso_spec) |> 
  add_recipe(fat_recipe)

fit_ridge <- workflow_ridge |> 
  fit(fat_train)

print("The parameters and r-squared of the LASSO prediction on the test set with lambda = 1:")

tidy(fit_ridge)

compare_pred <- augment(fit_ridge, new_data = fat_test) 

compare_pred |> rsq(brozek, .pred)


```

8.  Perform LASSO regression on the training set with parameter tuning, using k-fold validation. Make a plot of the rmse and r-squared as a function of lambda and report the best value of lambda.

    ```{r}
    fat_fold <- vfold_cv(fat_train, v = 10)

    lasso_recipe <- 
      recipe(brozek~ ., data = fat_train) |> 
      step_novel(all_nominal_predictors()) |>  
      step_dummy(all_nominal_predictors()) |>  
      step_zv(all_predictors()) |> 
      step_normalize(all_predictors())

    lasso_spec <- 
      linear_reg(penalty= tune(), mixture = 1) |> 
      set_mode("regression") |> 
      set_engine("glmnet")

    lasso_workflow <- workflow() |> 
      add_recipe(lasso_recipe) |> 
      add_model(lasso_spec)


    penalty_grid <- grid_regular(penalty(range = c(-5, 0)), levels = 50)


    tune_res <- tune_grid(
      lasso_workflow,
      resamples = fat_fold, 
      grid = penalty_grid
    )

    autoplot(tune_res)

    collect_metrics(tune_res)

    best_penalty<- select_best(tune_res, metric = "rmse")

    best_penalty
    ```

9.  Get the final model using the best penalty value, generate predictions on the test set, and report the parameter values and the r-squared on the test set.

```{r}
lasso_final <- finalize_workflow(lasso_workflow, best_penalty)

lasso_final_fit <- fit(lasso_final, data = fat_train)

augment(lasso_final_fit , new_data = fat_test) |>
  rsq(truth = brozek, estimate = .pred)

tidy(lasso_final_fit, penalty= best_penalty$penalty)
```

10. Comment on the performance of LASSO regression in comparison to ridge, in terms of both prediction quality and the value of the parameter values from the optimally tuned models.

LASSO seems to do consistently better, generating higher r-squared on the test set. IT also gives a simplified model, because several parameter values are set to 0.
